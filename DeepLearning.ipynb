{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, cohen_kappa_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Train = pd.read_csv('dataTrain.csv')\n",
    "Test = pd.read_csv('dataTest.csv')\n",
    "\n",
    "X_train = Train.drop('STATUS', axis=1)\n",
    "y_train = Train['STATUS']\n",
    "\n",
    "X_test = Test.drop('STATUS', axis=1)\n",
    "y_test = Test['STATUS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dnn(X, y, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "    best_metrics = {'accuracy': 0}\n",
    "    best_model = None\n",
    "    best_params = {}\n",
    "\n",
    "    for units in [64, 128, 256]:\n",
    "        for dropout_rate in [0.0, 0.2, 0.5]:\n",
    "            for activation in ['relu', 'tanh']:\n",
    "                fold_accuracies = []\n",
    "                for train_index, test_index in kf.split(X):\n",
    "                    model = Sequential([\n",
    "                        Input(shape=(X.shape[1],)),\n",
    "                        Dense(units, activation=activation),\n",
    "                        Dropout(dropout_rate),\n",
    "                        Dense(units // 2, activation=activation),\n",
    "                        Dropout(dropout_rate),\n",
    "                        Dense(1, activation='sigmoid')\n",
    "                    ])\n",
    "                    model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "                    \n",
    "                    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
    "                    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
    "                    \n",
    "                    model.fit(X_train_fold, y_train_fold, epochs=30, batch_size=16, verbose=0)\n",
    "                    y_pred = (model.predict(X_test_fold, verbose=0) > 0.5).astype(\"int32\")\n",
    "\n",
    "                    acc = accuracy_score(y_test_fold, y_pred)\n",
    "                    fold_accuracies.append(acc)\n",
    "                \n",
    "                avg_acc = np.mean(fold_accuracies)\n",
    "                if avg_acc > best_metrics['accuracy']:\n",
    "                    best_metrics['accuracy'] = avg_acc\n",
    "                    best_metrics['recall'] = recall_score(y_test_fold, y_pred)\n",
    "                    best_metrics['precision'] = precision_score(y_test_fold, y_pred)\n",
    "                    best_metrics['f1'] = f1_score(y_test_fold, y_pred)\n",
    "                    best_metrics['kappa'] = cohen_kappa_score(y_test_fold, y_pred)\n",
    "                    best_model = model\n",
    "                    best_params = {'units': units, 'dropout_rate': dropout_rate, 'activation': activation}\n",
    "    \n",
    "    print(\"Best DNN Model Results:\")\n",
    "    print(f\"Hyperparameters - Units: {best_params['units']}, Dropout Rate: {best_params['dropout_rate']}, Activation: {best_params['activation']}\")\n",
    "    print(f\"Accuracy: {best_metrics['accuracy']:.3f}\")\n",
    "    print(f\"Recall: {best_metrics['recall']:.3f}\")\n",
    "    print(f\"Precision: {best_metrics['precision']:.3f}\")\n",
    "    print(f\"F1-Score: {best_metrics['f1']:.3f}\")\n",
    "    print(f\"Kappa: {best_metrics['kappa']:.3f}\")\n",
    "\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp(X, y, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "    architectures = [[10], [20], [50], [10, 10], [20, 20], [50, 50], [100, 50], [100, 50, 25]]\n",
    "    solvers = ['adam', 'sgd']\n",
    "    activations = ['relu', 'tanh']\n",
    "    \n",
    "    best_metrics = {'accuracy': 0}\n",
    "    best_params = {}\n",
    "    best_model = None\n",
    "    \n",
    "    for hidden_layer_sizes in architectures:\n",
    "        for solver in solvers:\n",
    "            for activation in activations:\n",
    "                accuracies, recalls, precisions, f1_scores, kappas = [], [], [], [], []\n",
    "                \n",
    "                for train_index, test_index in kf.split(X):\n",
    "                    X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
    "                    y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "                    model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, solver=solver, activation=activation, random_state=1, max_iter=5000)\n",
    "                    model.fit(X_train_fold, y_train_fold)\n",
    "                    y_pred = model.predict(X_test_fold)\n",
    "                    \n",
    "                    accuracies.append(accuracy_score(y_test_fold, y_pred))\n",
    "                    recalls.append(recall_score(y_test_fold, y_pred, average='weighted'))\n",
    "                    precisions.append(precision_score(y_test_fold, y_pred, average='weighted'))\n",
    "                    f1_scores.append(f1_score(y_test_fold, y_pred, average='weighted'))\n",
    "                    kappas.append(cohen_kappa_score(y_test_fold, y_pred))\n",
    "                \n",
    "                avg_acc = np.mean(accuracies)\n",
    "                if avg_acc > best_metrics['accuracy']:\n",
    "                    best_metrics['accuracy'] = avg_acc\n",
    "                    best_metrics['recall'] = np.mean(recalls)\n",
    "                    best_metrics['precision'] = np.mean(precisions)\n",
    "                    best_metrics['f1'] = np.mean(f1_scores)\n",
    "                    best_metrics['kappa'] = np.mean(kappas)\n",
    "                    best_params = {'architecture': hidden_layer_sizes, 'solver': solver, 'activation': activation}\n",
    "                    best_model = model\n",
    "    \n",
    "    print(\"Best MLP Model Results:\")\n",
    "    print(f\"Architecture: {best_params['architecture']}, Solver: {best_params['solver']}, Activation: {best_params['activation']}\")\n",
    "    print(f\"Accuracy: {best_metrics['accuracy']:.3f}\")\n",
    "    print(f\"Recall: {best_metrics['recall']:.3f}\")\n",
    "    print(f\"Precision: {best_metrics['precision']:.3f}\")\n",
    "    print(f\"F1-Score: {best_metrics['f1']:.3f}\")\n",
    "    print(f\"Kappa: {best_metrics['kappa']:.3f}\")\n",
    "    \n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined_roc(models, X, y, model_names):\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    for model, name in zip(models, model_names):\n",
    "        y_pred_prob = model.predict_proba(X)[:, 0]  # Get probabilities for the positive class\n",
    "        fpr, tpr, _ = roc_curve(y, y_pred_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "    # Plot the chance line\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Chance')\n",
    "\n",
    "    # Plot settings\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best DNN Model Results:\n",
      "Hyperparameters - Units: 128, Dropout Rate: 0.0, Activation: tanh\n",
      "Accuracy: 0.965\n",
      "Recall: 0.961\n",
      "Precision: 0.967\n",
      "F1-Score: 0.964\n",
      "Kappa: 0.928\n",
      "Best MLP Model Results:\n",
      "Architecture: [100, 50], Solver: adam, Activation: tanh\n",
      "Accuracy: 0.973\n",
      "Recall: 0.973\n",
      "Precision: 0.973\n",
      "F1-Score: 0.973\n",
      "Kappa: 0.946\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m best_mlp_model \u001b[38;5;241m=\u001b[39m train_mlp(X_train, y_train)  \u001b[38;5;66;03m# Assuming this returns the best trained MLP model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Combine and plot\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mplot_combined_roc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mbest_dnn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_mlp_model\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBest DNN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBest MLP\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m, in \u001b[0;36mplot_combined_roc\u001b[1;34m(models, X, y, model_names)\u001b[0m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model, name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(models, model_names):\n\u001b[1;32m----> 6\u001b[0m     y_pred_prob \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m(X)[:, \u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Get probabilities for the positive class\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     fpr, tpr, _ \u001b[38;5;241m=\u001b[39m roc_curve(y, y_pred_prob)\n\u001b[0;32m      8\u001b[0m     roc_auc \u001b[38;5;241m=\u001b[39m auc(fpr, tpr)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_proba'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example integration with your existing code\n",
    "best_dnn_model = train_dnn(X_train, y_train)  # Assuming this returns the best trained DNN model\n",
    "best_mlp_model = train_mlp(X_train, y_train)  # Assuming this returns the best trained MLP model\n",
    "\n",
    "# Combine and plot\n",
    "plot_combined_roc(\n",
    "    models=[best_dnn_model, best_mlp_model],\n",
    "    X=X_test,\n",
    "    y=y_test,\n",
    "    model_names=[\"Best DNN\", \"Best MLP\"]\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IntelSis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
