{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyfume.Clustering import Clusterer\n",
    "from pyfume.EstimateAntecendentSet import AntecedentEstimator\n",
    "from pyfume.EstimateConsequentParameters import ConsequentEstimator\n",
    "from pyfume.SimpfulModelBuilder import SugenoFISBuilder\n",
    "from pyfume.Tester import SugenoFISTester\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, cohen_kappa_score\n",
    "from numpy import clip, column_stack, argmax\n",
    "from scipy.spatial import distance\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics import silhouette_score\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.read_csv('dataTrain.csv')\n",
    "Test = pd.read_csv('dataTest.csv')\n",
    "\n",
    "stats = pd.read_csv('stats.csv')\n",
    "stats = stats.iloc[:,1:]\n",
    "\n",
    "X_train = Train.drop('STATUS', axis=1)\n",
    "y_train = Train['STATUS']\n",
    "\n",
    "X_test = Test.drop('STATUS', axis=1)\n",
    "y_test = Test['STATUS']\n",
    "\n",
    "maxs = X_train.max().tolist()\n",
    "mins = X_train.min().tolist()\n",
    "\n",
    "var_names = X_train.columns.to_list()\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savecols = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_train = y_train.array\n",
    "y_test = y_test.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will try out different numbers of clusters in order to minimize the separation between clusters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SeparationMetric(X_train, clust_centers, part_matrix):\n",
    "    distances = cdist(X_train, clust_centers, metric=\"euclidean\")\n",
    "    metric = np.sum(part_matrix * distances)\n",
    "    return metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, mu, sigma, mux, sigx):\n",
    "    mu = mux + sigx * mu\n",
    "    sigma = sigma * sigx\n",
    "    z = (x - mu) / sigma\n",
    "    return np.exp(-0.5 * z**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Revert(x, stats):\n",
    "    for i in range(x.shape[0]):\n",
    "        data = stats[stats['Feature'] == savecols[i]]\n",
    "        x[i] = x[i] * (data.iloc[0,2] ** 0.5) + data.iloc[0,1]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_clusters = 10\n",
    "min_metric = np.inf\n",
    "selected_method = 'fst-pso' \n",
    "\n",
    "for i in range(max_clusters):\n",
    "    i += 1\n",
    "    cl = Clusterer(x_train=X_train, y_train=y_train, nr_clus=i)\n",
    "    clust_centers, part_matrix, _ = cl.cluster(method=selected_method)\n",
    "    clust_centers = clust_centers[:,:-1]\n",
    "    \n",
    "    metric = SeparationMetric(X_train, clust_centers, part_matrix)\n",
    "    if metric < min_metric:\n",
    "        min_metric = metric\n",
    "        best_number = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = Clusterer(x_train=X_train, y_train=y_train, nr_clus=best_number)\n",
    "clust_centers, part_matrix, _ = cl.cluster(method=selected_method, m=0.99)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(clust_centers, columns=savecols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = AntecedentEstimator(X_train, part_matrix)\n",
    "antecedent_params = ae.determineMF()\n",
    "\n",
    "ce = ConsequentEstimator(X_train, y_train, part_matrix)\n",
    "conseq_params = ce.suglms()\n",
    "\n",
    "modbuilder = SugenoFISBuilder(antecedent_params, conseq_params, var_names, save_simpful_code=False)\n",
    "model = modbuilder.get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modtester = SugenoFISTester(model, X_test, var_names)\n",
    "y_pred_probs = clip(modtester.predict()[0], 0, 1)\n",
    "a = modtester.predict()[0]\n",
    "y_pred_probs = column_stack((1 - y_pred_probs, y_pred_probs))\n",
    "y_pred = argmax(y_pred_probs,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:.3f}\".format(acc_score))\n",
    "rec_score = recall_score(y_test, y_pred)\n",
    "print(\"Recall: {:.3f}\".format(rec_score))\n",
    "prec_score = precision_score(y_test, y_pred)\n",
    "print(\"Precision Score: {:.3f}\".format(prec_score))\n",
    "F1_score = f1_score(y_test, y_pred)\n",
    "print(\"F1-Score: {:.3f}\".format(F1_score))\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print(\"Kappa Score: {:.3f}\".format(kappa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Visualization/Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._outputfunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._lvs['chol'] # example of how pyFUME defines une linguistic variable in simpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pyFUME library doesn't atribute a universe of discourse to the linguistic variables it creates in simpful. In order to fix this, we set each universe considering the maximum\n",
    "# value heald by each dataframe column. This has to be done since, otherwise, the plotting functions won't work.\n",
    "\n",
    "for ix in range(len(var_names)):\n",
    "    max = maxs[ix]\n",
    "    min = mins[ix]\n",
    "    uod = [min, max]\n",
    "    model._lvs[var_names[ix]]._universe_of_discourse = uod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.produce_figure(\"\",2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the model to X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UODtoX(model, stats):\n",
    "    uods = {}\n",
    "    for lv in model._lvs:\n",
    "        data = stats[stats['Feature'] == lv]\n",
    "        mean = data.iloc[0,1]\n",
    "        std = data.iloc[0,2] ** 0.5\n",
    "        uod = model._lvs[lv]._universe_of_discourse\n",
    "        for i in range(2):\n",
    "            uod[i] = uod[i] * std + mean\n",
    "        uods[lv] = uod\n",
    "    return uods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XMF:\n",
    "\n",
    "    def __init__(self, uod, data, mu, sigma):\n",
    "        self.uod = uod\n",
    "        self.mean = data.iloc[0,1]\n",
    "        self.std = data.iloc[0,2] ** 0.5\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __call__(self, x):\n",
    "        #x = (x - self.mean) / self.std # X to Z\n",
    "        x = gaussian(x, self.mu, self.sigma, self.mean, self.std) # Z to MF\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newMFS(model, stats, uods):\n",
    "    MFS = {}\n",
    "    for lv in model._lvs:\n",
    "        fs = []\n",
    "        data = stats[stats['Feature'] == lv]\n",
    "        uod = uods[lv]\n",
    "        for clust in range(len(model._lvs[lv]._FSlist)):\n",
    "            mu = model._lvs[lv]._FSlist[clust]._funpointer._mu\n",
    "            sigma = model._lvs[lv]._FSlist[clust]._funpointer._sigma\n",
    "            fs.append(XMF(uod, data, mu, sigma))\n",
    "        MFS[lv] = fs\n",
    "    return MFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMFs(mfs, var, save = False):\n",
    "    plt.clf()\n",
    "    mfs = mfs[var]\n",
    "    x = np.linspace(mfs[0].uod[0], mfs[0].uod[1], 100)\n",
    "    for i in range(len(mfs)):\n",
    "        y = [mfs[i](j) for j in x]\n",
    "        plt.plot(x, y)\n",
    "    plt.title(var)\n",
    "    plt.ylim((0, 1.1))\n",
    "    if save == True:\n",
    "        plt.savefig(var + '.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FunctionstoX(model, stats):\n",
    "    final_df = pd.DataFrame(columns = var_names+['constant'])\n",
    "\n",
    "    for f in model._outputfunctions:\n",
    "        acumulated = 0 # value to be added to the intercept in the end\n",
    "        expression = model._outputfunctions[f]\n",
    "        item_list = expression.split('+')\n",
    "\n",
    "        for k in range(len(item_list) - 1):\n",
    "            item_list[k] = item_list[k].split('*')\n",
    "            values = stats[stats['Feature'] == item_list[k][1]]\n",
    "            std = values.iloc[0,2] ** 0.5\n",
    "            mean = values.iloc[0,1]\n",
    "            acumulated -= float(item_list[k][0]) * mean / (std) \n",
    "            item_list[k] = float(item_list[k][0]) / (std) \n",
    "            \n",
    "        item_list[-1] = float(item_list[-1]) + acumulated\n",
    "        final_df = pd.concat([final_df,pd.DataFrame([item_list], columns = var_names+['constant'])], axis = 0)\n",
    "        final_df.reset_index(drop=True, inplace=True)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(X_test, mfs, consequents):\n",
    "\n",
    "    X = X_test.copy()\n",
    "    for i in range(best_number):\n",
    "        X[i] = Revert(X[i], stats)\n",
    "    y = [] # dim 1: weighted sum of the consequents for each cluster\n",
    "    dim = X.shape[1]\n",
    "    for i in range(X.shape[0]):\n",
    "        membership_list = []\n",
    "        for k in range(dim):\n",
    "            temp_list = [] # membership values for a certain variable. dim 1: clust\n",
    "            for clust in range(best_number):\n",
    "                temp_list.append(mfs[var_names[k]][clust](X[i,k]))\n",
    "            membership_list.append(temp_list)\n",
    "        membership_list = np.transpose(np.array(membership_list)) # membership values for a certain observation. dim 1: clust, dim 2: var\n",
    "        acumulated = 0\n",
    "        firing_strengths = 0\n",
    "        for h in range(best_number):\n",
    "            linear_sum = 0\n",
    "            for j in range(dim):\n",
    "                linear_sum += consequents.iloc[h,j] * X[i,j]\n",
    "            linear_sum += consequents.iloc[h,-1] # output of the linear function of cluster h\n",
    "            acumulated += linear_sum * np.min(membership_list[h]) \n",
    "            firing_strengths += np.min(membership_list[h])\n",
    "        acumulated = acumulated / firing_strengths\n",
    "        y.append(acumulated)\n",
    "\n",
    "    return np.array(y) # dim 1: observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uods = UODtoX(model, stats)\n",
    "mfs = newMFS(model, stats, uods)\n",
    "consequents = FunctionstoX(model, stats)\n",
    "#uods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(best_number):\n",
    "    clust_centers[i] = Revert(clust_centers[i], stats)\n",
    "clust_centers = pd.DataFrame(clust_centers, columns = var_names)\n",
    "clust_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: clustering is not deterministic, generated images may be different from the ones in the report\n",
    "\n",
    "plotMFs(mfs, 'thalachh', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all figures\n",
    "# Warning: clustering is not deterministic, generated images may be different from the ones in the report\n",
    "# Comented so new figures are not generated every time the notebook is run\n",
    "\n",
    "for i in var_names: \n",
    "    #plotMFs(mfs, i, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consequents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference(X_test, mfs, consequents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IntelSis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
